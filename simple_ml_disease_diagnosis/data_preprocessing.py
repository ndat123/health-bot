"""
Module ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu ti·∫øng Vi·ªát cho ch·∫©n ƒëo√°n b·ªánh
X·ª≠ l√Ω:
- Chu·∫©n h√≥a vƒÉn b·∫£n ti·∫øng Vi·ªát
- Lo·∫°i b·ªè d·∫•u (n·∫øu c·∫ßn)
- X·ª≠ l√Ω missing values
- L√†m s·∫°ch text
"""

import re
import unicodedata
import pandas as pd
from typing import Tuple, Optional


class VietnameseTextPreprocessor:
    """Class x·ª≠ l√Ω vƒÉn b·∫£n ti·∫øng Vi·ªát"""
    
    def __init__(self, remove_accents: bool = False):
        """
        Kh·ªüi t·∫°o preprocessor
        
        Args:
            remove_accents: C√≥ lo·∫°i b·ªè d·∫•u ti·∫øng Vi·ªát kh√¥ng (m·∫∑c ƒë·ªãnh: False)
        """
        self.remove_accents = remove_accents
        
        # Stopwords ti·∫øng Vi·ªát ƒë∆°n gi·∫£n
        self.stopwords = {
            't√¥i', 'b·ªã', 'ƒëang', 'c√≥', 'th·ªÉ', 'l√†', 'c·ªßa', 'v√†', 'c√°c',
            'ƒë∆∞·ª£c', 'cho', 't·ª´', 'v·ªõi', 'n√†y', 'ƒë·ªÉ', 'trong', 'kh√¥ng',
            'c√≥ th·ªÉ', 'g√¨', 'c·∫£m th·∫•y', 'hi·ªán', 'hay', 'ƒë√£'
        }
    
    def remove_vietnamese_accents(self, text: str) -> str:
        """
        Lo·∫°i b·ªè d·∫•u ti·∫øng Vi·ªát
        
        Args:
            text: VƒÉn b·∫£n ƒë·∫ßu v√†o
            
        Returns:
            VƒÉn b·∫£n kh√¥ng d·∫•u
        """
        if not text:
            return ""
        
        # Normalize unicode
        text = unicodedata.normalize('NFD', text)
        
        # Lo·∫°i b·ªè c√°c k√Ω t·ª± d·∫•u
        text = ''.join(char for char in text 
                      if unicodedata.category(char) != 'Mn')
        
        # X·ª≠ l√Ω c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát ti·∫øng Vi·ªát
        replacements = {
            'ƒë': 'd', 'ƒê': 'D',
            '√∞': 'd', '√ê': 'D'
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        return text
    
    def clean_text(self, text: str) -> str:
        """
        L√†m s·∫°ch vƒÉn b·∫£n
        
        Args:
            text: VƒÉn b·∫£n ƒë·∫ßu v√†o
            
        Returns:
            VƒÉn b·∫£n ƒë√£ l√†m s·∫°ch
        """
        if not isinstance(text, str):
            return ""
        
        # Chuy·ªÉn v·ªÅ lowercase
        text = text.lower()
        
        # Lo·∫°i b·ªè d·∫•u n·∫øu c·∫ßn
        if self.remove_accents:
            text = self.remove_vietnamese_accents(text)
        
        # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát, gi·ªØ l·∫°i ch·ªØ c√°i, s·ªë v√† kho·∫£ng tr·∫Øng
        text = re.sub(r'[^\w\s]', ' ', text)
        
        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def remove_stopwords(self, text: str) -> str:
        """
        Lo·∫°i b·ªè stopwords
        
        Args:
            text: VƒÉn b·∫£n ƒë·∫ßu v√†o
            
        Returns:
            VƒÉn b·∫£n ƒë√£ lo·∫°i b·ªè stopwords
        """
        words = text.split()
        filtered_words = [word for word in words if word not in self.stopwords]
        return ' '.join(filtered_words)
    
    def preprocess(self, text: str, remove_stopwords: bool = False) -> str:
        """
        Ti·ªÅn x·ª≠ l√Ω ho√†n ch·ªânh
        
        Args:
            text: VƒÉn b·∫£n ƒë·∫ßu v√†o
            remove_stopwords: C√≥ lo·∫°i b·ªè stopwords kh√¥ng
            
        Returns:
            VƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        """
        text = self.clean_text(text)
        
        if remove_stopwords:
            text = self.remove_stopwords(text)
        
        return text


class DiseaseDataLoader:
    """Class load v√† x·ª≠ l√Ω d·ªØ li·ªáu b·ªánh"""
    
    def __init__(self, csv_path: str, remove_accents: bool = False):
        """
        Kh·ªüi t·∫°o data loader
        
        Args:
            csv_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file CSV
            remove_accents: C√≥ lo·∫°i b·ªè d·∫•u kh√¥ng
        """
        self.csv_path = csv_path
        self.preprocessor = VietnameseTextPreprocessor(remove_accents)
        self.df = None
        self.disease_mapping = {}
        self.reverse_mapping = {}
    
    def load_data(self) -> pd.DataFrame:
        """
        Load d·ªØ li·ªáu t·ª´ CSV
        
        Returns:
            DataFrame ƒë√£ x·ª≠ l√Ω
        """
        print(f"üìÇ ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´: {self.csv_path}")
        
        # ƒê·ªçc CSV
        self.df = pd.read_csv(self.csv_path)
        
        print(f"‚úì ƒê√£ ƒë·ªçc {len(self.df)} d√≤ng d·ªØ li·ªáu")
        
        # Ki·ªÉm tra columns
        required_columns = ['Disease', 'Question']
        for col in required_columns:
            if col not in self.df.columns:
                raise ValueError(f"Thi·∫øu c·ªôt '{col}' trong dataset!")
        
        return self.df
    
    def handle_missing_values(self) -> pd.DataFrame:
        """
        X·ª≠ l√Ω gi√° tr·ªã b·ªã thi·∫øu
        
        Returns:
            DataFrame ƒë√£ x·ª≠ l√Ω
        """
        print("\nüîç Ki·ªÉm tra d·ªØ li·ªáu thi·∫øu...")
        
        # ƒê·∫øm gi√° tr·ªã thi·∫øu
        missing_counts = self.df.isnull().sum()
        
        if missing_counts.sum() > 0:
            print(f"‚ö†Ô∏è  T√¨m th·∫•y {missing_counts.sum()} gi√° tr·ªã thi·∫øu:")
            for col, count in missing_counts.items():
                if count > 0:
                    print(f"   - {col}: {count} d√≤ng")
            
            # Lo·∫°i b·ªè c√°c d√≤ng c√≥ gi√° tr·ªã thi·∫øu
            before = len(self.df)
            self.df = self.df.dropna()
            after = len(self.df)
            print(f"‚úì ƒê√£ lo·∫°i b·ªè {before - after} d√≤ng c√≥ d·ªØ li·ªáu thi·∫øu")
        else:
            print("‚úì Kh√¥ng c√≥ d·ªØ li·ªáu thi·∫øu")
        
        return self.df
    
    def preprocess_text(self, remove_stopwords: bool = False) -> pd.DataFrame:
        """
        Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
        
        Args:
            remove_stopwords: C√≥ lo·∫°i b·ªè stopwords kh√¥ng
            
        Returns:
            DataFrame ƒë√£ x·ª≠ l√Ω
        """
        print("\nüîß ƒêang ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n...")
        
        # X·ª≠ l√Ω c·ªôt Question
        self.df['Question_Processed'] = self.df['Question'].apply(
            lambda x: self.preprocessor.preprocess(x, remove_stopwords)
        )
        
        # X·ª≠ l√Ω c·ªôt Disease (ƒë·ªÉ ƒë·ªìng nh·∫•t)
        self.df['Disease_Processed'] = self.df['Disease'].apply(
            lambda x: str(x).strip()
        )
        
        print("‚úì Ho√†n th√†nh ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n")
        
        return self.df
    
    def create_disease_mapping(self) -> Tuple[dict, dict]:
        """
        T·∫°o mapping gi·ªØa t√™n b·ªánh v√† ID s·ªë
        
        Returns:
            Tuple (disease_to_id, id_to_disease)
        """
        print("\nüóÇÔ∏è  T·∫°o mapping b·ªánh...")
        
        # L·∫•y danh s√°ch c√°c b·ªánh duy nh·∫•t
        unique_diseases = sorted(self.df['Disease_Processed'].unique())
        
        # T·∫°o mapping
        self.disease_mapping = {disease: idx for idx, disease in enumerate(unique_diseases)}
        self.reverse_mapping = {idx: disease for disease, idx in self.disease_mapping.items()}
        
        # Th√™m c·ªôt label (ID s·ªë)
        self.df['label'] = self.df['Disease_Processed'].map(self.disease_mapping)
        
        print(f"‚úì ƒê√£ t·∫°o mapping cho {len(unique_diseases)} lo·∫°i b·ªánh")
        
        return self.disease_mapping, self.reverse_mapping
    
    def get_statistics(self) -> dict:
        """
        L·∫•y th·ªëng k√™ v·ªÅ dataset
        
        Returns:
            Dictionary ch·ª©a th·ªëng k√™
        """
        stats = {
            'total_samples': len(self.df),
            'num_diseases': len(self.disease_mapping),
            'samples_per_disease': self.df['label'].value_counts().to_dict(),
            'avg_question_length': self.df['Question_Processed'].apply(len).mean(),
            'min_samples': self.df['label'].value_counts().min(),
            'max_samples': self.df['label'].value_counts().max(),
        }
        
        return stats
    
    def print_statistics(self):
        """In th·ªëng k√™ dataset"""
        stats = self.get_statistics()
        
        print("\n" + "="*70)
        print("üìä TH·ªêNG K√ä DATASET")
        print("="*70)
        print(f"T·ªïng s·ªë m·∫´u: {stats['total_samples']:,}")
        print(f"S·ªë lo·∫°i b·ªánh: {stats['num_diseases']}")
        print(f"ƒê·ªô d√†i c√¢u h·ªèi trung b√¨nh: {stats['avg_question_length']:.1f} k√Ω t·ª±")
        print(f"S·ªë m·∫´u √≠t nh·∫•t cho 1 b·ªánh: {stats['min_samples']}")
        print(f"S·ªë m·∫´u nhi·ªÅu nh·∫•t cho 1 b·ªánh: {stats['max_samples']}")
        
        # Top 5 b·ªánh c√≥ nhi·ªÅu m·∫´u nh·∫•t
        top_diseases = sorted(stats['samples_per_disease'].items(), 
                            key=lambda x: x[1], reverse=True)[:5]
        print(f"\nüìà Top 5 b·ªánh c√≥ nhi·ªÅu m·∫´u nh·∫•t:")
        for label_id, count in top_diseases:
            disease_name = self.reverse_mapping[label_id]
            print(f"   {disease_name}: {count} m·∫´u")
        
        print("="*70)
    
    def prepare_data(self, remove_stopwords: bool = False) -> pd.DataFrame:
        """
        Pipeline x·ª≠ l√Ω d·ªØ li·ªáu ho√†n ch·ªânh
        
        Args:
            remove_stopwords: C√≥ lo·∫°i b·ªè stopwords kh√¥ng
            
        Returns:
            DataFrame ƒë√£ x·ª≠ l√Ω ho√†n ch·ªânh
        """
        print("\nüöÄ B·∫ÆT ƒê·∫¶U TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU")
        print("="*70)
        
        # Load data
        self.load_data()
        
        # X·ª≠ l√Ω missing values
        self.handle_missing_values()
        
        # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
        self.preprocess_text(remove_stopwords)
        
        # T·∫°o mapping
        self.create_disease_mapping()
        
        # In th·ªëng k√™
        self.print_statistics()
        
        return self.df


# Test module
if __name__ == "__main__":
    # Test preprocessor
    print("Test Vietnamese Text Preprocessor:")
    print("="*70)
    
    preprocessor = VietnameseTextPreprocessor(remove_accents=False)
    
    test_texts = [
        "T√¥i ƒëang c·∫£m th·∫•y ƒëau ƒë·∫ßu, s·ªët cao v√† m·ªát m·ªèi.",
        "T√¥i hay b·ªã bu·ªìn n√¥n, ch√≥ng m·∫∑t v√† kh√≥ th·ªü.",
        "T√¥i hi·ªán ƒëang c√≥ c√°c tri·ªáu ch·ª©ng nh∆∞ ho, s·ªï m≈©i v√† ƒëau h·ªçng."
    ]
    
    for text in test_texts:
        cleaned = preprocessor.preprocess(text, remove_stopwords=False)
        print(f"G·ªëc: {text}")
        print(f"X·ª≠ l√Ω: {cleaned}")
        print()
    
    # Test data loader (n·∫øu c√≥ file CSV)
    import os
    if os.path.exists("ViMedical_Disease.csv"):
        print("\n" + "="*70)
        print("Test Data Loader:")
        print("="*70)
        
        loader = DiseaseDataLoader("ViMedical_Disease.csv", remove_accents=False)
        df = loader.prepare_data(remove_stopwords=False)
        
        print(f"\n‚úì Dataset ƒë√£ s·∫µn s√†ng v·ªõi {len(df)} m·∫´u!")
        print(f"‚úì Columns: {list(df.columns)}")
        print(f"\nM·∫´u d·ªØ li·ªáu ƒë·∫ßu ti√™n:")
        print(df[['Disease_Processed', 'Question_Processed', 'label']].head(1))


