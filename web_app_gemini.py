"""
Web App cho Disease Diagnosis vá»›i Groq API
Cháº¡y trÃªn localhost vá»›i Flask
"""
from flask import Flask, render_template, request, jsonify
import os
from groq import Groq
try:
    import warnings
    # Suppress the deprecation warning for google.generativeai
    warnings.filterwarnings('ignore', category=FutureWarning, module='google.generativeai')
    import google.generativeai as genai
except ImportError:
    # Fallback if google-generativeai not installed
    genai = None
    print("âš  Google Generative AI not installed. Gemini engine will not be available.")
    print("  Install: pip install google-generativeai")
import pandas as pd
import mysql.connector
from mysql.connector import Error
from datetime import datetime

app = Flask(__name__)

# ============================================================================
# DUAL AI ENGINE CONFIGURATION - Groq + Google Gemini
# ============================================================================

# Configure Groq
# Get API key from environment variable or use placeholder
GROQ_API_KEY = os.getenv('GROQ_API_KEY', 'your_groq_api_key_here')
if GROQ_API_KEY == 'your_groq_api_key_here':
    print("âš  WARNING: GROQ_API_KEY not set. Please set it in environment variable or .env file")
    print("  Example: export GROQ_API_KEY='your_key_here'")
groq_client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY != 'your_groq_api_key_here' else None
GROQ_MODEL = 'llama-3.3-70b-versatile'  # Model máº¡nh nháº¥t cá»§a Groq

# Configure Google Gemini
# Get API key from environment variable or use placeholder
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', 'your_gemini_api_key_here')
if genai:
    try:
        if GEMINI_API_KEY != 'your_gemini_api_key_here':
            genai.configure(api_key=GEMINI_API_KEY)
            print("âœ“ Gemini API configured successfully")
        else:
            print("âš  WARNING: GEMINI_API_KEY not set. Gemini engine will not be available.")
            print("  Example: export GEMINI_API_KEY='your_key_here'")
    except Exception as e:
        print(f"âš  Gemini API configuration error: {e}")

# Gemini model options:
# 1. Base model (not tuned): 'gemini-2.0-flash-exp'
# 2. Fine-tuned model: 'tunedModels/your-model-name' (after training)
GEMINI_MODEL = 'gemini-2.0-flash-exp'  # Default: base model
GEMINI_TUNED_MODEL = None  # Set this after fine-tuning: 'tunedModels/xxx'

# Default AI engine
DEFAULT_AI_ENGINE = 'groq'  # 'groq' or 'gemini'

# MySQL Configuration
DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': 'root',
    'database': 'healthcare'
}

# Initialize database
def init_database():
    """Táº¡o báº£ng search_history náº¿u chÆ°a tá»“n táº¡i.

    LÆ¯U Ã:
    - TrÃªn mÃ´i trÆ°á»ng nhÆ° Railway, náº¿u khÃ´ng cÃ³ MySQL (localhost:3306),
      hÃ m nÃ y pháº£i FAIL GRACEFULLY, KHÃ”NG Ä‘Æ°á»£c lÃ m app crash.
    """
    conn = None
    cursor = None
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        cursor = conn.cursor()

        # Create table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS search_history (
                id INT AUTO_INCREMENT PRIMARY KEY,
                symptoms TEXT NOT NULL,
                disease VARCHAR(255) NOT NULL,
                analysis TEXT,
                confidence FLOAT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_created_at (created_at),
                INDEX idx_disease (disease)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        """)

        conn.commit()
        print("âœ“ Database table 'search_history' initialized successfully")

    except Error as e:
        # KhÃ´ng lÃ m app dá»«ng â€“ chá»‰ log lá»—i, app váº«n cháº¡y bÃ¬nh thÆ°á»ng
        print(f"âœ— Database error: {e}")
        print("âš  Database features (search history) will be disabled on this environment.")
    finally:
        try:
            if conn is not None and hasattr(conn, "is_connected") and conn.is_connected():
                if cursor is not None:
                    cursor.close()
                conn.close()
        except Exception:
            # Tuyá»‡t Ä‘á»‘i khÃ´ng cho lá»—i á»Ÿ Ä‘Ã¢y lÃ m app crash
            pass

def get_db_connection():
    """Táº¡o káº¿t ná»‘i database"""
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        return conn
    except Error as e:
        print(f"Database connection error: {e}")
        return None

def save_search_history(symptoms, disease, analysis, confidence=0):
    """LÆ°u lá»‹ch sá»­ tÃ¬m kiáº¿m vÃ o database"""
    try:
        conn = get_db_connection()
        if not conn:
            return False
            
        cursor = conn.cursor()
        query = """
            INSERT INTO search_history (symptoms, disease, analysis, confidence)
            VALUES (%s, %s, %s, %s)
        """
        cursor.execute(query, (symptoms, disease, analysis, confidence))
        conn.commit()
        
        print(f"âœ“ Saved search history: {disease}")
        return True
        
    except Error as e:
        print(f"Error saving history: {e}")
        return False
    finally:
        if conn and conn.is_connected():
            cursor.close()
            conn.close()

# Prediction Strategy Config
CSV_CONFIDENCE_THRESHOLD = 100  # Náº¿u score >= threshold â†’ dÃ¹ng CSV, khÃ´ng gá»i API
# TÄƒng threshold Ä‘á»ƒ Æ°u tiÃªn API hÆ¡n
# Giáº£m threshold Ä‘á»ƒ Æ°u tiÃªn CSV hÆ¡n (nhanh, tiáº¿t kiá»‡m API calls)

# Load diseases and build knowledge base
df = pd.read_csv('ViMedical_Disease.csv', encoding='utf-8')
diseases = sorted(df['Disease'].unique().tolist())

# Build disease knowledge base: disease -> list of symptom descriptions
disease_symptoms = {}
for disease in diseases:
    disease_data = df[df['Disease'] == disease]['Question'].tolist()
    # Láº¥y tá»‘i Ä‘a 10 máº«u triá»‡u chá»©ng cho má»—i bá»‡nh Ä‘á»ƒ giáº£m token
    disease_symptoms[disease] = disease_data[:10]

print(f"âœ“ Loaded {len(diseases)} diseases with {len(df)} symptom samples")

# Initialize database
init_database()

def validate_symptoms_input(text):
    """
    Kiá»ƒm tra xem input cÃ³ pháº£i lÃ  triá»‡u chá»©ng y táº¿ hay khÃ´ng
    Tráº£ vá» (is_valid, message)
    """
    import re
    
    # Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
    text = text.strip()
    
    # Kiá»ƒm tra Ä‘á»™ dÃ i tá»‘i thiá»ƒu
    if len(text) < 5:
        return False, "Vui lÃ²ng mÃ´ táº£ triá»‡u chá»©ng chi tiáº¿t hÆ¡n (Ã­t nháº¥t 5 kÃ½ tá»±)"
    
    # Keywords liÃªn quan Ä‘áº¿n triá»‡u chá»©ng y táº¿
    medical_keywords = [
        'Ä‘au', 'sá»‘t', 'ho', 'nÃ´n', 'chÃ³ng máº·t', 'má»‡t', 'buá»“n nÃ´n', 'tiÃªu cháº£y',
        'khÃ³ thá»Ÿ', 'ngá»©a', 'phÃ¡t ban', 'sÆ°ng', 'viÃªm', 'cháº£y mÃ¡u', 'xuáº¥t huyáº¿t',
        'run', 'co giáº­t', 'tÃª', 'tÃª liá»‡t', 'yáº¿u', 'má»i', 'Ä‘au Ä‘áº§u', 'nhá»©c',
        'khÃ³ nuá»‘t', 'khÃ n', 'ho khan', 'ho cÃ³ Ä‘á»m', 'sá»• mÅ©i', 'ngháº¹t mÅ©i',
        'á»›n láº¡nh', 'vÃ£ má»“ hÃ´i', 'khÃ¡t nÆ°á»›c', 'chÃ¡n Äƒn', 'sá»¥t cÃ¢n', 'tÄƒng cÃ¢n',
        'tÃ¡o bÃ³n', 'tiá»ƒu', 'phÃ¢n', 'kinh nguyá»‡t', 'Ä‘au bá»¥ng', 'Ä‘au ngá»±c',
        'khÃ³ chá»‹u', 'tá»©c ngá»±c', 'há»“i há»™p', 'lo Ã¢u', 'máº¥t ngá»§', 'buá»“n ngá»§',
        'cháº£y nÆ°á»›c mÅ©i', 'Ä‘au há»ng', 'sÆ°ng há»ng', 'khÃ³ thá»Ÿ', 'thá»Ÿ khÃ² khÃ¨',
        'ho ra mÃ¡u', 'nÃ´n ra mÃ¡u', 'phÃ¹', 'sÆ°ng phÃ¹', 'Ä‘au lÆ°ng', 'Ä‘au cÆ¡',
        'cá»©ng khá»›p', 'Ä‘au khá»›p', 'vÃ ng da', 'ngá»©a', 'ná»•i máº©n', 'báº§m tÃ­m',
        'cháº£y mÃ¡u cam', 'Ã¹ tai', 'nhÃ¬n má»', 'hoa máº¯t', 'ngáº¥t', 'choÃ¡ng vÃ¡ng'
    ]
    
    # CÃ¡c tá»« chá»‰ vá»‹ trÃ­ / cÆ¡ thá»ƒ
    body_parts = [
        'Ä‘áº§u', 'cá»•', 'há»ng', 'ngá»±c', 'bá»¥ng', 'lÆ°ng', 'tay', 'chÃ¢n', 'vai', 'gá»‘i',
        'máº¯t', 'tai', 'mÅ©i', 'miá»‡ng', 'rÄƒng', 'lÆ°á»¡i', 'da', 'tÃ³c', 'mÃ³ng',
        'tim', 'phá»•i', 'gan', 'tháº­n', 'dáº¡ dÃ y', 'ruá»™t', 'bÃ ng quang'
    ]
    
    # Kiá»ƒm tra cÃ³ keyword y táº¿ khÃ´ng
    text_lower = text.lower()
    has_medical_keyword = any(keyword in text_lower for keyword in medical_keywords)
    has_body_part = any(part in text_lower for part in body_parts)
    
    # Náº¿u cÃ³ keyword y táº¿ hoáº·c body part â†’ cÃ³ thá»ƒ lÃ  triá»‡u chá»©ng
    if has_medical_keyword or has_body_part:
        return True, None
    
    # Kiá»ƒm tra cÃ¡c cÃ¢u há»i khÃ´ng liÃªn quan
    invalid_patterns = [
        r'(báº¡n lÃ  ai|báº¡n tÃªn gÃ¬|ai táº¡o ra báº¡n)',
        r'(thá»i tiáº¿t|trá»i|mÆ°a|náº¯ng)',
        r'(chÃ o|hello|hi|xin chÃ o)',
        r'(cáº£m Æ¡n|thank)',
        r'(táº¡m biá»‡t|bye|goodbye)',
        r'(bao nhiÃªu tuá»•i|nÄƒm nay)',
        r'(á»Ÿ Ä‘Ã¢u|Ä‘á»‹a chá»‰|nÆ¡i nÃ o)',
        r'(lÃ m gÃ¬|cÃ´ng viá»‡c)',
        r'(thÃ­ch gÃ¬|sá»Ÿ thÃ­ch)',
        r'(mÃ u|sá»‘|ngÃ y)',
        r'^(a|b|c|d|e|1|2|3)$',  # Chá»‰ 1 kÃ½ tá»±
        r'^test$',
        r'(test|thá»­|demo)',
    ]
    
    for pattern in invalid_patterns:
        if re.search(pattern, text_lower):
            return False, "âŒ CÃ¢u há»i khÃ´ng há»£p lá»‡! Vui lÃ²ng nháº­p triá»‡u chá»©ng bá»‡nh (vÃ­ dá»¥: Ä‘au Ä‘áº§u, sá»‘t cao, ho khan...)"
    
    # Náº¿u text quÃ¡ ngáº¯n vÃ  khÃ´ng cÃ³ keyword y táº¿
    if len(text) < 10 and not (has_medical_keyword or has_body_part):
        return False, "Vui lÃ²ng mÃ´ táº£ triá»‡u chá»©ng chi tiáº¿t hÆ¡n. VÃ­ dá»¥: 'TÃ´i bá»‹ Ä‘au Ä‘áº§u, sá»‘t cao vÃ  buá»“n nÃ´n'"
    
    # Sá»­ dá»¥ng Groq API Ä‘á»ƒ validate (náº¿u váº«n khÃ´ng cháº¯c cháº¯n)
    if not has_medical_keyword and not has_body_part:
        try:
            validation_prompt = f"""Báº¡n lÃ  há»‡ thá»‘ng AI y táº¿. Kiá»ƒm tra xem cÃ¢u sau cÃ³ pháº£i lÃ  mÃ´ táº£ triá»‡u chá»©ng bá»‡nh hay khÃ´ng:

"{text}"

Tráº£ lá»i CHá»ˆ Má»˜T Tá»ª: "CÃ“" hoáº·c "KHÃ”NG"
- CÃ“: náº¿u Ä‘Ã¢y lÃ  triá»‡u chá»©ng bá»‡nh, váº¥n Ä‘á» sá»©c khá»e
- KHÃ”NG: náº¿u Ä‘Ã¢y lÃ  cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n sá»©c khá»e/triá»‡u chá»©ng"""

            response = groq_client.chat.completions.create(
                model=GROQ_MODEL,
                messages=[
                    {"role": "system", "content": "Báº¡n lÃ  AI validator, chá»‰ tráº£ lá»i CÃ“ hoáº·c KHÃ”NG"},
                    {"role": "user", "content": validation_prompt}
                ],
                temperature=0.1,
                max_tokens=10,
            )
            
            answer = response.choices[0].message.content.strip().upper()
            
            if 'KHÃ”NG' in answer or 'NO' in answer:
                return False, "âŒ CÃ¢u há»i khÃ´ng há»£p lá»‡! Vui lÃ²ng nháº­p triá»‡u chá»©ng bá»‡nh (vÃ­ dá»¥: Ä‘au Ä‘áº§u, sá»‘t cao, ho khan...)"
            
        except Exception as e:
            print(f"Validation API error: {e}")
            # Náº¿u API lá»—i, cho phÃ©p tiáº¿p tá»¥c (fail-safe)
            pass
    
    # Default: cho phÃ©p náº¿u khÃ´ng cÃ³ dáº¥u hiá»‡u rÃµ rÃ ng lÃ  invalid
    return True, None

def get_disease_detail_from_ai(disease_name, ai_engine='groq'):
    """
    Gá»i AI API (Groq hoáº·c Gemini) Ä‘á»ƒ láº¥y thÃ´ng tin chi tiáº¿t vá» má»™t bá»‡nh cá»¥ thá»ƒ
    
    Args:
        disease_name: TÃªn bá»‡nh cáº§n láº¥y thÃ´ng tin
        ai_engine: 'groq' hoáº·c 'gemini'
    """
    import re
    
    prompt = f"""Báº¡n lÃ  bÃ¡c sÄ© chuyÃªn khoa. HÃ£y cung cáº¥p thÃ´ng tin CHI TIáº¾T vá» bá»‡nh: **{disease_name}**

TRáº¢ Lá»œI THEO FORMAT:

ğŸ©º Triá»‡u chá»©ng Ä‘áº§y Ä‘á»§:
- [Triá»‡u chá»©ng 1 - cá»¥ thá»ƒ vÃ  chi tiáº¿t]
- [Triá»‡u chá»©ng 2]
- [Triá»‡u chá»©ng 3]
- [Triá»‡u chá»©ng 4]
- [Triá»‡u chá»©ng 5]

ğŸ’Š CÃ¡ch chá»¯a/Ä‘iá»u trá»‹:
- [PhÆ°Æ¡ng phÃ¡p Ä‘iá»u trá»‹ 1 - cá»¥ thá»ƒ]
- [PhÆ°Æ¡ng phÃ¡p Ä‘iá»u trá»‹ 2]
- [PhÆ°Æ¡ng phÃ¡p Ä‘iá»u trá»‹ 3]
- [PhÆ°Æ¡ng phÃ¡p Ä‘iá»u trá»‹ 4]
- [PhÆ°Æ¡ng phÃ¡p Ä‘iá»u trá»‹ 5]

âš ï¸ NguyÃªn nhÃ¢n:
- [NguyÃªn nhÃ¢n 1 - cá»¥ thá»ƒ]
- [NguyÃªn nhÃ¢n 2]
- [NguyÃªn nhÃ¢n 3]
- [NguyÃªn nhÃ¢n 4]

âš•ï¸ Khi nÃ o cáº§n Ä‘i khÃ¡m gáº¥p:
- [Dáº¥u hiá»‡u nguy hiá»ƒm 1]
- [Dáº¥u hiá»‡u nguy hiá»ƒm 2]

LÆ¯U Ã:
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
- Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c, khoa há»c
- Giá»¯ ÄÃšNG format trÃªn"""

    try:
        if ai_engine == 'gemini':
            # Call Google Gemini API
            model_name = GEMINI_TUNED_MODEL if GEMINI_TUNED_MODEL else GEMINI_MODEL
            model = genai.GenerativeModel(model_name)
            
            response = model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,
                    max_output_tokens=1500,
                )
            )
            
            result_text = response.text
            
        else:  # Default: groq
            # Call Groq API
            response = groq_client.chat.completions.create(
                model=GROQ_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "Báº¡n lÃ  bÃ¡c sÄ© chuyÃªn khoa giÃ u kinh nghiá»‡m, cung cáº¥p thÃ´ng tin y táº¿ chÃ­nh xÃ¡c báº±ng tiáº¿ng Viá»‡t."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=1500,
            )
            
            result_text = response.choices[0].message.content
        
        # Parse response
        symptoms = []
        treatment = []
        causes = []
        urgent_signs = []
        
        # Extract symptoms
        symptoms_match = re.search(r'ğŸ©º\s*Triá»‡u chá»©ng Ä‘áº§y Ä‘á»§:(.*?)(?=ğŸ’Š|âš ï¸|âš•ï¸|$)', result_text, re.DOTALL | re.IGNORECASE)
        if symptoms_match:
            symptoms_text = symptoms_match.group(1)
            symptoms = re.findall(r'[-â€¢]\s*([^\n]+)', symptoms_text)
            symptoms = [s.strip() for s in symptoms if len(s.strip()) > 5][:10]
        
        # Extract treatment
        treatment_match = re.search(r'ğŸ’Š\s*CÃ¡ch chá»¯a/Ä‘iá»u trá»‹:(.*?)(?=âš ï¸|âš•ï¸|$)', result_text, re.DOTALL | re.IGNORECASE)
        if treatment_match:
            treatment_text = treatment_match.group(1)
            treatment = re.findall(r'[-â€¢]\s*([^\n]+)', treatment_text)
            treatment = [t.strip() for t in treatment if len(t.strip()) > 5][:10]
        
        # Extract causes
        causes_match = re.search(r'âš ï¸\s*NguyÃªn nhÃ¢n:(.*?)(?=âš•ï¸|ğŸ’Š|$)', result_text, re.DOTALL | re.IGNORECASE)
        if causes_match:
            causes_text = causes_match.group(1)
            causes = re.findall(r'[-â€¢]\s*([^\n]+)', causes_text)
            causes = [c.strip() for c in causes if len(c.strip()) > 5][:8]
        
        # Extract urgent signs
        urgent_match = re.search(r'âš•ï¸\s*Khi nÃ o cáº§n Ä‘i khÃ¡m gáº¥p:(.*?)(?=\n\n|$)', result_text, re.DOTALL | re.IGNORECASE)
        if urgent_match:
            urgent_text = urgent_match.group(1)
            urgent_signs = re.findall(r'[-â€¢]\s*([^\n]+)', urgent_text)
            urgent_signs = [u.strip() for u in urgent_signs if len(u.strip()) > 5][:5]
        
        if symptoms or treatment or causes:
            return {
                'disease_name': disease_name,
                'symptoms': symptoms if symptoms else ['Triá»‡u chá»©ng sáº½ Ä‘Æ°á»£c cáº­p nháº­t sau khi Ä‘i khÃ¡m'],
                'treatment': treatment if treatment else ['Vui lÃ²ng Ä‘i khÃ¡m bÃ¡c sÄ© Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n Ä‘iá»u trá»‹ cá»¥ thá»ƒ'],
                'causes': causes if causes else ['Nhiá»u nguyÃªn nhÃ¢n khÃ¡c nhau, cáº§n khÃ¡m Ä‘á»ƒ xÃ¡c Ä‘á»‹nh'],
                'urgent_signs': urgent_signs if urgent_signs else []
            }
    
    except Exception as e:
        print(f"Error getting disease detail from Groq: {e}")
    
    # Fallback náº¿u cÃ³ lá»—i
    return {
        'disease_name': disease_name,
        'symptoms': ['Vui lÃ²ng Ä‘i khÃ¡m Ä‘á»ƒ bÃ¡c sÄ© Ä‘Ã¡nh giÃ¡ triá»‡u chá»©ng cá»¥ thá»ƒ'],
        'treatment': ['Äiá»u trá»‹ phá»¥ thuá»™c vÃ o cháº©n Ä‘oÃ¡n chÃ­nh xÃ¡c tá»« bÃ¡c sÄ©'],
        'causes': ['Nhiá»u nguyÃªn nhÃ¢n cÃ³ thá»ƒ gÃ¢y ra bá»‡nh nÃ y'],
        'urgent_signs': []
    }

def find_relevant_diseases(symptoms_input, top_k=15):
    """
    TÃ¬m cÃ¡c bá»‡nh cÃ³ triá»‡u chá»©ng tÆ°Æ¡ng tá»± vá»›i input cá»§a user
    DÃ¹ng TF-IDF Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c
    """
    from collections import Counter, defaultdict
    import re
    import math
    
    # Stopwords tiáº¿ng Viá»‡t (cÃ¡c tá»« khÃ´ng quan trá»ng)
    stopwords = {
        'tÃ´i', 'cá»§a', 'cÃ³', 'bá»‹', 'Ä‘ang', 'lÃ ', 'vÃ ', 'nÃ y', 'thá»ƒ', 'cÃ¡c', 'vá»›i',
        'má»™t', 'Ä‘Æ°á»£c', 'hay', 'Ä‘á»ƒ', 'khi', 'nhÆ°', 'thÃ¬', 'nÃ o', 'lÃ m', 'trong',
        'tá»«', 'cho', 'vá»', 'ngÆ°á»i', 'nhá»¯ng', 'khÃ´ng', 'cÃ³ thá»ƒ', 'gÃ¬', 'hiá»‡n',
        'cáº£m', 'triá»‡u', 'chá»©ng'
    }
    
    # Normalize input
    symptoms_lower = symptoms_input.lower()
    
    # Extract keywords (cÃ¡c tá»« quan trá»ng)
    keywords = re.findall(r'\w+', symptoms_lower)
    keywords = [k for k in keywords if len(k) > 2 and k not in stopwords]
    
    # Extract phrases (2-3 tá»«)
    words = symptoms_lower.split()
    phrases = []
    for i in range(len(words) - 1):
        phrase = f"{words[i]} {words[i+1]}"
        if len(phrase) > 8:  # Chá»‰ láº¥y phrase dÃ i
            phrases.append(phrase)
    
    # TÃ­nh IDF cho má»—i keyword (sá»‘ bá»‡nh cÃ³ keyword nÃ y)
    keyword_idf = defaultdict(int)
    for disease, symptom_list in disease_symptoms.items():
        disease_text = " ".join(symptom_list).lower()
        for keyword in set(keywords):  # Chá»‰ Ä‘áº¿m 1 láº§n má»—i keyword cho má»—i bá»‡nh
            if keyword in disease_text:
                keyword_idf[keyword] += 1
    
    # TÃ­nh IDF score: log(total_diseases / diseases_with_keyword)
    total_diseases = len(disease_symptoms)
    idf_scores = {}
    for keyword, count in keyword_idf.items():
        if count > 0:
            # Keyword cÃ ng hiáº¿m (Ã­t bá»‡nh cÃ³) -> IDF cÃ ng cao
            idf_scores[keyword] = math.log(total_diseases / count)
    
    # Score cho má»—i bá»‡nh vá»›i TF-IDF
    disease_scores = {}
    disease_matching_symptoms = {}
    
    for disease, symptom_list in disease_symptoms.items():
        disease_text = " ".join(symptom_list).lower()
        score = 0
        matching_symptoms = []
        
        # Score tá»« keywords vá»›i IDF weighting
        for keyword in keywords:
            if keyword in disease_text:
                # TF: sá»‘ láº§n xuáº¥t hiá»‡n
                tf = disease_text.count(keyword)
                # IDF: Ä‘á»™ hiáº¿m cá»§a keyword
                idf = idf_scores.get(keyword, 0)
                # TF-IDF score
                score += tf * idf * 10  # NhÃ¢n 10 Ä‘á»ƒ scale
        
        # Bonus score cho exact phrases
        for phrase in phrases:
            if phrase in disease_text:
                score += 50  # Bonus cao cho phrase khá»›p
        
        # TÃ¬m matching symptoms
        for symptom_text in symptom_list:
            symptom_lower = symptom_text.lower()
            matches = sum(1 for keyword in keywords if keyword in symptom_lower)
            if matches > 0:
                matching_symptoms.append(symptom_text.strip())
        
        if score > 0:
            disease_scores[disease] = score
            disease_matching_symptoms[disease] = matching_symptoms[:3]
    
    # Láº¥y top k bá»‡nh cÃ³ score cao nháº¥t
    top_diseases = sorted(disease_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]
    
    # Build context vá»›i thÃ´ng tin chi tiáº¿t hÆ¡n
    context = ""
    context += f"\nğŸ” TÃ¬m tháº¥y {len(top_diseases)} bá»‡nh khá»›p vá»›i triá»‡u chá»©ng:\n"
    
    for i, (disease, score) in enumerate(top_diseases[:15], 1):  # Top 15
        symptoms = disease_matching_symptoms.get(disease, [])
        if symptoms:
            # Normalize score Ä‘á»ƒ dá»… hiá»ƒu (0-100)
            normalized_score = min(100, int(score / max(1, top_diseases[0][1]) * 100))
            context += f"\n{i}. **{disease}** (relevance: {normalized_score}%):\n"
            
            for symptom in symptoms[:3]:  # Láº¥y 3 triá»‡u chá»©ng Ä‘iá»ƒn hÃ¬nh
                # Extract triá»‡u chá»©ng tá»« cÃ¢u há»i
                symptom_clean = symptom.replace("TÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬?", "")
                symptom_clean = symptom_clean.replace('"', '').strip()
                # Loáº¡i bá» "TÃ´i Ä‘ang..." Ä‘á»ƒ chá»‰ giá»¯ triá»‡u chá»©ng
                symptom_clean = re.sub(r'^(TÃ´i|Bá»‡nh nhÃ¢n)\s+(Ä‘ang|hiá»‡n Ä‘ang|Ä‘ang cáº£m tháº¥y|cáº£m tháº¥y|hay bá»‹|bá»‹)\s+', '', symptom_clean)
                symptom_clean = re.sub(r'^\s*cÃ³ cÃ¡c triá»‡u chá»©ng nhÆ°\s+', '', symptom_clean)
                if symptom_clean and len(symptom_clean) > 10:
                    context += f"   â€¢ {symptom_clean}\n"
    
    # Return context, diseases list, and best match info
    best_match_score = top_diseases[0][1] if top_diseases else 0
    return context, [d for d, s in top_diseases], best_match_score, top_diseases

def predict_from_csv_data(symptoms_input, top_diseases_with_scores, ai_engine='groq'):
    """
    Dá»± Ä‘oÃ¡n trá»±c tiáº¿p tá»« dá»¯ liá»‡u CSV vÃ  láº¥y chi tiáº¿t tá»« AI
    
    Args:
        symptoms_input: Triá»‡u chá»©ng ngÆ°á»i dÃ¹ng nháº­p
        top_diseases_with_scores: List of (disease, score) tuples
        ai_engine: 'groq' hoáº·c 'gemini'
    """
    import re
    
    if not top_diseases_with_scores:
        return None
    
    # Get top 1 disease vá»›i thÃ´ng tin Ä‘áº§y Ä‘á»§
    detailed_predictions = []
    total_score = sum(score for _, score in top_diseases_with_scores[:1])
    
    for i, (disease, score) in enumerate(top_diseases_with_scores[:1]):
        # TÃ­nh xÃ¡c suáº¥t dá»±a trÃªn score
        if total_score > 0:
            probability = int((score / total_score) * 100)
        else:
            probability = 0
        
        # KhÃ´ng hiá»ƒn thá»‹ % ná»¯a
        probability = 0
        
        # Táº¡o reason chi tiáº¿t
        reason = f"Triá»‡u chá»©ng khá»›p tá»‘t nháº¥t vá»›i {disease} trong database vá»›i {len(disease_symptoms.get(disease, []))} máº«u triá»‡u chá»©ng tÆ°Æ¡ng tá»±"
        
        # Láº¥y triá»‡u chá»©ng Ä‘iá»ƒn hÃ¬nh tá»« database
        typical_symptoms = []
        if disease in disease_symptoms:
            symptom_samples = disease_symptoms[disease][:5]  # Top 5
            for symptom in symptom_samples:
                clean = symptom.replace("TÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬?", "").replace('"', '').strip()
                clean = re.sub(r'^(TÃ´i|Bá»‡nh nhÃ¢n)\s+(Ä‘ang|hiá»‡n Ä‘ang|Ä‘ang cáº£m tháº¥y|cáº£m tháº¥y|hay bá»‹|bá»‹)\s+', '', clean)
                clean = re.sub(r'^\s*cÃ³ cÃ¡c triá»‡u chá»©ng nhÆ°\s+', '', clean)
                if clean and len(clean) > 10:
                    typical_symptoms.append(clean)
        
        # Äáº¿m sá»‘ máº«u trong database
        sample_count = len(df[df['Disease'] == disease])
        
        detailed_predictions.append({
            'disease': disease,
            'probability': probability,
            'reason': reason,
            'typical_symptoms': typical_symptoms[:3],  # Top 3 triá»‡u chá»©ng
            'database_samples': sample_count,
            'has_database_info': len(typical_symptoms) > 0
        })
    
    # Táº¡o analysis
    top_disease = top_diseases_with_scores[0][0]
    analysis = f"Dá»±a trÃªn phÃ¢n tÃ­ch 23,521 máº«u trong database, triá»‡u chá»©ng cá»§a báº¡n khá»›p nháº¥t vá»›i {top_disease}"
    
    # Gá»i AI API Ä‘á»ƒ láº¥y thÃ´ng tin chi tiáº¿t vá» bá»‡nh Ä‘áº§u tiÃªn
    disease_info = None
    if detailed_predictions:
        top_disease_name = detailed_predictions[0]['disease']
        disease_info = get_disease_detail_from_ai(top_disease_name, ai_engine=ai_engine)
    
    # Recommendations chung
    recommendations = [
        f"Äi khÃ¡m bÃ¡c sÄ© chuyÃªn khoa Ä‘á»ƒ xÃ¡c Ä‘á»‹nh chÃ­nh xÃ¡c",
        "Theo dÃµi cÃ¡c triá»‡u chá»©ng vÃ  ghi chÃ©p láº¡i",
        "KhÃ´ng tá»± Ã½ Ä‘iá»u trá»‹ khi chÆ°a cÃ³ cháº©n Ä‘oÃ¡n",
        "Nghá»‰ ngÆ¡i Ä‘áº§y Ä‘á»§ vÃ  giá»¯ tinh tháº§n thoáº£i mÃ¡i"
    ]
    
    return {
        'success': True,
        'analysis': analysis,
        'predictions': detailed_predictions,
        'disease_info': disease_info,
        'recommendations': recommendations,
        'warning': 'ÄÃ¢y lÃ  dá»± Ä‘oÃ¡n AI dá»±a trÃªn database, KHÃ”NG PHáº¢I cháº©n Ä‘oÃ¡n y táº¿. HÃ£y Ä‘i khÃ¡m bÃ¡c sÄ© Ä‘á»ƒ Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n chÃ­nh xÃ¡c!',
        'metadata': {
            'source': 'CSV Database (23,521 máº«u)',
            'model': 'TF-IDF + Keyword Matching',
            'provider': 'Local Database'
        }
    }

# System instruction vá»›i examples
SYSTEM_INSTRUCTION = f"""Báº¡n lÃ  trá»£ lÃ½ y táº¿ AI chuyÃªn nghiá»‡p Ä‘Æ°á»£c training trÃªn database {len(diseases)} loáº¡i bá»‡nh tiáº¿ng Viá»‡t vá»›i {len(df)} máº«u triá»‡u chá»©ng.

DATABASE Báº N ÄÃƒ Há»ŒC BAO Gá»’M:
- CÃ¡c bá»‡nh phá»¥ khoa: á»i Vá»¡ Non, Sinh Non, Tiá»n Sáº£n Giáº­t, BÄƒng Huyáº¿t Sau Sinh...
- CÃ¡c bá»‡nh nhiá»…m trÃ¹ng: Sá»‘t Xuáº¥t Huyáº¿t, CÃºm, COVID-19, ViÃªm Phá»•i...  
- CÃ¡c bá»‡nh tiÃªu hÃ³a: ViÃªm Dáº¡ DÃ y, ViÃªm Ruá»™t, LoÃ©t Dáº¡ DÃ y...
- VÃ  {len(diseases)-50} bá»‡nh khÃ¡c

NHIá»†M Vá»¤: 
1. Äá»c ká»¹ "THÃ”NG TIN Tá»ª DATABASE" Ä‘Æ°á»£c cung cáº¥p (Ä‘Ã£ lá»c sáºµn cÃ¡c bá»‡nh cÃ³ triá»‡u chá»©ng tÆ°Æ¡ng tá»±)
2. So sÃ¡nh triá»‡u chá»©ng cá»§a user vá»›i triá»‡u chá»©ng trong database
3. Dá»± Ä‘oÃ¡n 3-5 bá»‡nh CÃ“ TRONG DATABASE vá»›i xÃ¡c suáº¥t dá»±a trÃªn Ä‘á»™ khá»›p.

VÃ Dá»¤ OUTPUT CHUáº¨N:

ğŸ” PhÃ¢n tÃ­ch: Triá»‡u chá»©ng sÆ°ng cá»•, khÃ³ nuá»‘t vÃ  khÃ n tiáº¿ng cÃ³ thá»ƒ gáº·p á»Ÿ nhiá»u bá»‡nh khÃ¡c nhau

ğŸ’¡ Dá»± Ä‘oÃ¡n bá»‡nh:

1. **BÆ°á»›u Cá»• LÃ nh TÃ­nh** - 60%
   LÃ½ do: Triá»‡u chá»©ng khá»›p vá»›i bÆ°á»›u cá»•, nhÆ°ng khÃ´ng cÃ³ dáº¥u hiá»‡u Ã¡c tÃ­nh nhÆ° sá»¥t cÃ¢n, ho ra mÃ¡u

2. **Ung ThÆ° Thanh Quáº£n** - 30%
   LÃ½ do: CÃ³ triá»‡u chá»©ng tÆ°Æ¡ng tá»± nhÆ°ng thiáº¿u dáº¥u hiá»‡u Ä‘áº·c trÆ°ng nhÆ° ho ra mÃ¡u, tiá»n sá»­ hÃºt thuá»‘c

3. **ViÃªm Thanh Quáº£n** - 10%
   LÃ½ do: CÃ³ thá»ƒ gÃ¢y khÃ n tiáº¿ng vÃ  khÃ³ nuá»‘t táº¡m thá»i

ğŸ“‹ THÃ”NG TIN CHI TIáº¾T Vá»€ BÆ¯á»šU Cá»” LÃ€NH TÃNH:

ğŸ©º Triá»‡u chá»©ng Ä‘áº§y Ä‘á»§:
- SÆ°ng to vÃ¹ng cá»•, cÃ³ thá»ƒ tháº¥y khá»‘i u lá»›n dáº§n
- KhÃ³ nuá»‘t, cáº£m giÃ¡c ngháº¹n khi Äƒn uá»‘ng
- KhÃ n tiáº¿ng do chÃ¨n Ã©p thanh quáº£n
- KhÃ³ thá»Ÿ khi gáº¯ng sá»©c hoáº·c náº±m ngá»­a
- Má»‡t má»i, tÄƒng cÃ¢n hoáº·c giáº£m cÃ¢n
- Da khÃ´, rá»¥ng tÃ³c (náº¿u suy giÃ¡p)
- Lo láº¯ng, Ä‘Ã¡nh trá»‘ng ngá»±c (náº¿u cÆ°á»ng giÃ¡p)

ğŸ’Š CÃ¡ch chá»¯a/Ä‘iá»u trá»‹:
- Theo dÃµi Ä‘á»‹nh ká»³ náº¿u u nhá», khÃ´ng triá»‡u chá»©ng
- DÃ¹ng thuá»‘c Ä‘iá»u chá»‰nh hormone giÃ¡p
- Äiá»u trá»‹ iod phÃ³ng xáº¡ náº¿u cÆ°á»ng giÃ¡p
- Pháº«u thuáº­t cáº¯t bá» u náº¿u u lá»›n, chÃ¨n Ã©p
- Bá»• sung iod náº¿u thiáº¿u iod
- TrÃ¡nh stress, nghá»‰ ngÆ¡i Ä‘áº§y Ä‘á»§

âš ï¸ NguyÃªn nhÃ¢n:
- Thiáº¿u iod trong cháº¿ Ä‘á»™ Äƒn
- Rá»‘i loáº¡n hormone tuyáº¿n giÃ¡p
- Di truyá»n, tiá»n sá»­ gia Ä‘Ã¬nh
- Stress kÃ©o dÃ i, thiáº¿u ngá»§

ğŸ’Š Khuyáº¿n nghá»‹:
- Äi khÃ¡m bÃ¡c sÄ© ná»™i tiáº¿t Ä‘á»ƒ xÃ©t nghiá»‡m hormone giÃ¡p
- SiÃªu Ã¢m tuyáº¿n giÃ¡p Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kÃ­ch thÆ°á»›c u
- XÃ©t nghiá»‡m táº¿ bÃ o há»c náº¿u nghi ngá» Ã¡c tÃ­nh
- Theo dÃµi Ä‘á»‹nh ká»³ 6 thÃ¡ng/láº§n

QUY Táº®C QUAN TRá»ŒNG:
1. LUÃ”N match triá»‡u chá»©ng vá»›i bá»‡nh trong database
2. DÃ¹ng % pháº£n Ã¡nh Ä‘á»™ cháº¯c cháº¯n:
   - 85-95%: Triá»‡u chá»©ng Ráº¤T ÄIá»‚N HÃŒNH, khá»›p hoÃ n toÃ n
   - 70-84%: Triá»‡u chá»©ng khá»›p tá»‘t, nhiá»u dáº¥u hiá»‡u Ä‘áº·c trÆ°ng
   - 50-69%: Triá»‡u chá»©ng cÃ³ thá»ƒ, thiáº¿u má»™t sá»‘ dáº¥u hiá»‡u
   - 30-49%: Kháº£ nÄƒng tháº¥p
   - 10-29%: Ráº¥t Ã­t kháº£ nÄƒng
3. KHÃ”NG ngáº¡i Ä‘Æ°a ra 85-95% náº¿u triá»‡u chá»©ng ráº¥t rÃµ rÃ ng vÃ  Ä‘iá»ƒn hÃ¬nh
4. Vá»›i triá»‡u chá»©ng thai sáº£n (á»‘i, nÆ°á»›c á»‘i, xuáº¥t huyáº¿t thai ká»³) â†’ nghÄ© Ä‘áº¿n bá»‡nh phá»¥ khoa
5. Giá»¯ ÄÃšNG format trÃªn, khÃ´ng thÃªm text khÃ¡c
6. TÃªn bá»‡nh pháº£i CHÃNH XÃC theo tiáº¿ng Viá»‡t"""

@app.route('/')
def index():
    return render_template('index.html', total_diseases=len(diseases))

@app.route('/predict', methods=['POST'])
def predict():
    try:
        data = request.get_json()
        symptoms = data.get('symptoms', '').strip()
        ai_engine = data.get('ai_engine', DEFAULT_AI_ENGINE).lower()  # Get AI engine from request
        
        # Validate AI engine
        if ai_engine not in ['groq', 'gemini', 'groq_chat']:
            print(f"âš ï¸ Invalid AI engine '{ai_engine}', defaulting to '{DEFAULT_AI_ENGINE}'")
            ai_engine = DEFAULT_AI_ENGINE
        
        print(f"\n{'='*70}")
        print(f"ğŸ¤– AI Engine Selected: {ai_engine.upper()}")
        print(f"Symptoms: {symptoms[:80]}...")
        print(f"{'='*70}")
        
        if not symptoms:
            return jsonify({'error': 'Vui lÃ²ng nháº­p triá»‡u chá»©ng'}), 400
        
        # === CHATBOT MODES (Skip database search, go direct to AI) ===
        if ai_engine in ['groq_chat', 'gemini']:
            print(f"\n{'='*70}")
            print(f"ğŸ’¬ CHATBOT MODE: {ai_engine.upper()}")
            print(f"{'='*70}")
            print(f"Input: {symptoms[:100]}...")
            print("Mode: Direct conversation (no database search)")
            
            # GROQ CHATBOT
            if ai_engine == 'groq_chat':
                try:
                    # Create conversational prompt for Groq
                    chatbot_system = """Báº¡n lÃ  bÃ¡c sÄ© AI thÃ¢n thiá»‡n, chuyÃªn tÆ° váº¥n sá»©c khá»e qua chat.

PHONG CÃCH TRáº¢ Lá»œI:
- ThÃ¢n thiá»‡n, dá»… hiá»ƒu, khÃ´ng quÃ¡ formal
- Giáº£i thÃ­ch chi tiáº¿t vá» bá»‡nh vÃ  triá»‡u chá»©ng
- LuÃ´n an á»§i vÃ  Ä‘á»™ng viÃªn bá»‡nh nhÃ¢n
- ÄÆ°a ra lá»i khuyÃªn cá»¥ thá»ƒ vÃ  thá»±c táº¿
- Nháº¥n máº¡nh táº§m quan trá»ng cá»§a viá»‡c Ä‘i khÃ¡m bÃ¡c sÄ©

KHÃ”NG:
- KhÃ´ng chá»‰ liá»‡t kÃª tÃªn bá»‡nh
- KhÃ´ng dÃ¹ng ngÃ´n ngá»¯ y khoa quÃ¡ phá»©c táº¡p
- KhÃ´ng gÃ¢y hoáº£ng sá»£ cho bá»‡nh nhÃ¢n

FORMAT TRáº¢ Lá»œI:
1. XÃ¡c nháº­n vÃ  tháº¥u hiá»ƒu triá»‡u chá»©ng
2. Giáº£i thÃ­ch kháº£ nÄƒng máº¯c bá»‡nh gÃ¬
3. MÃ´ táº£ chi tiáº¿t vá» bá»‡nh Ä‘Ã³
4. Lá»i khuyÃªn vÃ  hÆ°á»›ng xá»­ lÃ½
5. Äá»™ng viÃªn vÃ  nháº¯c nhá»Ÿ Ä‘i khÃ¡m

VÃ Dá»¤:
User: "TÃ´i bá»‹ Ä‘au Ä‘áº§u vÃ  sá»‘t"
Bot: "Dá»±a vÃ o cÃ¡c triá»‡u chá»©ng báº¡n mÃ´ táº£, báº¡n cÃ³ thá»ƒ Ä‘ang gáº·p pháº£i tÃ¬nh tráº¡ng cáº£m láº¡nh hoáº·c cÃºm.

**Vá» tÃ¬nh tráº¡ng nÃ y:**
Äau Ä‘áº§u kÃ¨m sá»‘t lÃ  dáº¥u hiá»‡u cá»§a nhiá»…m trÃ¹ng Ä‘Æ°á»ng hÃ´ háº¥p trÃªn, thÆ°á»ng gáº·p nháº¥t lÃ  cáº£m láº¡nh hoáº·c cÃºm. ÄÃ¢y lÃ  tÃ¬nh tráº¡ng khÃ¡ phá»• biáº¿n vÃ  thÆ°á»ng cÃ³ thá»ƒ tá»± khá»i sau 5-7 ngÃ y.

**Lá»i khuyÃªn:**
- Nghá»‰ ngÆ¡i nhiá»u, uá»‘ng Ä‘á»§ nÆ°á»›c
- CÃ³ thá»ƒ dÃ¹ng thuá»‘c háº¡ sá»‘t nhÆ° paracetamol náº¿u sá»‘t trÃªn 38.5Â°C
- Theo dÃµi triá»‡u chá»©ng

**Khi nÃ o cáº§n Ä‘i khÃ¡m gáº¥p:**
- Sá»‘t trÃªn 39Â°C kÃ©o dÃ i > 3 ngÃ y
- Äau Ä‘áº§u dá»¯ dá»™i, buá»“n nÃ´n
- KhÃ³ thá»Ÿ, Ä‘au ngá»±c

Tuy nhiÃªn, Ä‘á»ƒ cháº¯c cháº¯n vÃ  Ä‘Æ°á»£c tÆ° váº¥n cá»¥ thá»ƒ hÆ¡n, báº¡n nÃªn Ä‘áº¿n gáº·p bÃ¡c sÄ© Ä‘á»ƒ Ä‘Æ°á»£c khÃ¡m vÃ  cháº©n Ä‘oÃ¡n chÃ­nh xÃ¡c nhÃ©!

ChÃºc báº¡n mau khá»e! ğŸ’™\""""
                    
                    response = groq_client.chat.completions.create(
                        model=GROQ_MODEL,
                        messages=[
                            {
                                "role": "system",
                                "content": chatbot_system
                            },
                            {
                                "role": "user",
                                "content": symptoms
                            }
                        ],
                        temperature=0.7,  # Higher for natural conversation
                        max_tokens=2000,
                        top_p=0.9,
                    )
                    
                    chat_response = response.choices[0].message.content
                    
                    print(f"\n{'='*70}")
                    print("RAW RESPONSE FROM GROQ CHATBOT:")
                    print(f"Text length: {len(chat_response)} chars")
                    print(f"Content:\n{chat_response}")
                    print(f"{'='*70}\n")
                    
                    # Return chatbot-style response
                    result = {
                        'success': True,
                        'chat_response': chat_response,
                        'is_chatbot': True,
                        'ai_engine': 'groq_chat',
                        'analysis': 'Groq Ä‘ang tÆ° váº¥n cho báº¡n...',
                        'predictions': [],
                        'recommendations': [],
                        'warning': 'ÄÃ¢y lÃ  tÆ° váº¥n tá»« AI, khÃ´ng thay tháº¿ cháº©n Ä‘oÃ¡n y táº¿ chuyÃªn nghiá»‡p.',
                    }
                    
                    # Save to history
                    import re
                    disease_match = re.search(r'\*\*([^*]+)\*\*', chat_response)
                    disease_name = disease_match.group(1) if disease_match else "TÆ° váº¥n chung"
                    save_search_history(symptoms, disease_name, chat_response[:500], 0)
                    
                    return jsonify(result)
                    
                except Exception as e:
                    print(f"âŒ Groq Chatbot Error: {e}")
                    return jsonify({
                        'error': f'Lá»—i khi xá»­ lÃ½: {str(e)}',
                        'chat_response': f'Xin lá»—i, tÃ´i gáº·p sá»± cá»‘ khi xá»­ lÃ½ cÃ¢u há»i cá»§a báº¡n. Lá»—i: {str(e)[:100]}',
                        'is_chatbot': True,
                        'ai_engine': 'groq_chat'
                    }), 500
        
        # === GEMINI: CHATBOT MODE (Conversational) ===
        if ai_engine == 'gemini':
            print("ğŸ’¬ Gemini Chatbot Mode: Natural conversation")
            
            # Check if Gemini is available
            if not genai:
                return jsonify({
                    'error': 'Gemini API chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t. Vui lÃ²ng cÃ i Ä‘áº·t: pip install google-generativeai',
                    'chat_response': 'Xin lá»—i, Gemini AI chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t. Vui lÃ²ng liÃªn há»‡ quáº£n trá»‹ viÃªn Ä‘á»ƒ cÃ i Ä‘áº·t Google Generative AI.',
                    'is_chatbot': True,
                    'ai_engine': 'gemini'
                }), 500
            
            try:
                model_name = GEMINI_TUNED_MODEL if GEMINI_TUNED_MODEL else GEMINI_MODEL
                model = genai.GenerativeModel(model_name)
                
                # Simple, natural prompt for chatbot
                chatbot_prompt = symptoms
                
                response = model.generate_content(
                    chatbot_prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.7,  # Higher for more natural conversation
                        max_output_tokens=2000,
                        top_p=0.9,
                    )
                )
                
                chat_response = response.text
                
                print(f"\n{'='*70}")
                print("RAW RESPONSE FROM GEMINI CHATBOT:")
                print(f"Text length: {len(chat_response)} chars")
                print(f"Content:\n{chat_response}")
                print(f"{'='*70}\n")
                
                # Return chatbot-style response (khÃ´ng parse nhÆ° Groq)
                result = {
                    'success': True,
                    'chat_response': chat_response,  # Full conversational response
                    'is_chatbot': True,
                    'ai_engine': 'gemini',
                    'analysis': 'Gemini Ä‘ang tÆ° váº¥n cho báº¡n...',
                    'predictions': [],  # No structured predictions for chatbot mode
                    'recommendations': [],
                    'warning': 'ÄÃ¢y lÃ  tÆ° váº¥n tá»« AI, khÃ´ng thay tháº¿ cháº©n Ä‘oÃ¡n y táº¿ chuyÃªn nghiá»‡p.',
                }
                
                # Save to history
                # Extract disease name if mentioned in response (simple extraction)
                import re
                disease_match = re.search(r'\*\*([^*]+)\*\*', chat_response)
                disease_name = disease_match.group(1) if disease_match else "TÆ° váº¥n chung"
                save_search_history(symptoms, disease_name, chat_response[:500], 0)
                
                return jsonify(result)
                
            except Exception as e:
                print(f"âŒ Gemini API Error: {e}")
                error_message = str(e)
                
                # Friendly error messages
                if 'API_KEY_INVALID' in error_message or 'API key' in error_message:
                    friendly_error = 'Xin lá»—i, API key cá»§a Gemini chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘Ãºng. Vui lÃ²ng liÃªn há»‡ quáº£n trá»‹ viÃªn Ä‘á»ƒ cáº­p nháº­t API key.'
                elif 'quota' in error_message.lower() or 'limit' in error_message.lower():
                    friendly_error = 'Xin lá»—i, Gemini API Ä‘Ã£ háº¿t quota. Vui lÃ²ng thá»­ láº¡i sau hoáº·c liÃªn há»‡ quáº£n trá»‹ viÃªn.'
                elif 'not found' in error_message.lower():
                    friendly_error = 'Xin lá»—i, model Gemini khÃ´ng tÃ¬m tháº¥y. CÃ³ thá»ƒ model chÆ°a Ä‘Æ°á»£c fine-tune hoáº·c tÃªn model khÃ´ng Ä‘Ãºng.'
                else:
                    friendly_error = f'Xin lá»—i, tÃ´i gáº·p sá»± cá»‘ khi xá»­ lÃ½ cÃ¢u há»i cá»§a báº¡n. Chi tiáº¿t: {error_message[:100]}'
                
                return jsonify({
                    'error': friendly_error,
                    'chat_response': friendly_error,
                    'is_chatbot': True,
                    'ai_engine': 'gemini',
                    'technical_error': error_message
                }), 500
        
        # === GROQ: DIAGNOSIS MODE (Structured) ===
        # Only for diagnosis mode - validate and search database
        
        print(f"\n{'='*70}")
        print("âš¡ GROQ DIAGNOSIS MODE")
        print(f"{'='*70}")
        
        # Validate input
        is_valid, error_message = validate_symptoms_input(symptoms)
        if not is_valid:
            return jsonify({
                'error': error_message,
                'analysis': 'Há»‡ thá»‘ng chá»‰ há»— trá»£ cháº©n Ä‘oÃ¡n bá»‡nh dá»±a trÃªn triá»‡u chá»©ng',
                'predictions': [],
                'recommendations': [
                    'Vui lÃ²ng nháº­p triá»‡u chá»©ng cá»¥ thá»ƒ nhÆ°: Ä‘au Ä‘áº§u, sá»‘t, ho, buá»“n nÃ´n...',
                    'MÃ´ táº£ chi tiáº¿t: vá»‹ trÃ­ Ä‘au, má»©c Ä‘á»™, thá»i gian xuáº¥t hiá»‡n',
                    'VÃ­ dá»¥: "TÃ´i bá»‹ Ä‘au Ä‘áº§u dá»¯ dá»™i, sá»‘t cao 39 Ä‘á»™, buá»“n nÃ´n"'
                ],
                'warning': 'âš ï¸ CÃ¢u há»i khÃ´ng há»£p lá»‡. Vui lÃ²ng nháº­p triá»‡u chá»©ng bá»‡nh!'
            }), 400
        
        # Find relevant diseases from database
        relevant_context, relevant_diseases, best_match_score, top_diseases_with_scores = find_relevant_diseases(symptoms, top_k=20)
        
        print(f"\nğŸ” Found {len(relevant_diseases)} relevant diseases from database")
        print(f"Top 5: {relevant_diseases[:5]}")
        print(f"Best match score: {best_match_score}")
        
        # If high confidence match, use CSV prediction
        if best_match_score >= CSV_CONFIDENCE_THRESHOLD and len(top_diseases_with_scores) >= 3:
            print(f"âœ… Using CSV prediction (score: {best_match_score} >= {CSV_CONFIDENCE_THRESHOLD})")
            result = predict_from_csv_data(symptoms, top_diseases_with_scores, ai_engine=ai_engine)
            
            if result:
                print(f"ğŸ“Š CSV Predictions: {[p['disease'] for p in result['predictions'][:3]]}")
                result['ai_engine'] = ai_engine
                return jsonify(result)
        
        # Enhanced prompt vá»›i knowledge base tá»« CSV + thÃ´ng tin chi tiáº¿t
        print(f"ğŸ¤– Using Groq API for detailed diagnosis")
        prompt = f"""Báº¡n lÃ  bÃ¡c sÄ© AI chuyÃªn nghiá»‡p vá»›i database {len(diseases)} bá»‡nh tiáº¿ng Viá»‡t.

THÃ”NG TIN Tá»ª DATABASE (cÃ¡c bá»‡nh vÃ  triá»‡u chá»©ng liÃªn quan Ä‘áº¿n input):
{relevant_context}

---

TRIá»†U CHá»¨NG Cá»¦A Bá»†NH NHÃ‚N: "{symptoms}"

NHIá»†M Vá»¤: 
1. PhÃ¢n tÃ­ch triá»‡u chá»©ng vÃ  Ä‘Æ°a ra 1 Bá»†NH cÃ³ kháº£ nÄƒng cao nháº¥t dá»±a trÃªn thÃ´ng tin tá»« database
2. Cung cáº¥p THÃ”NG TIN CHI TIáº¾T vá» bá»‡nh Ä‘Ã³

QUY Táº®C XÃC SUáº¤T (QUAN TRá»ŒNG):
- 85-95%: Triá»‡u chá»©ng Ráº¤T ÄIá»‚N HÃŒNH + cÃ³ dáº¥u hiá»‡u Äáº¶C TRÆ¯NG RIÃŠNG cá»§a bá»‡nh Ä‘Ã³ (vÃ­ dá»¥: "ho ra mÃ¡u" cho ung thÆ° thanh quáº£n)
- 70-84%: Triá»‡u chá»©ng khá»›p tá»‘t, cÃ³ nhiá»u dáº¥u hiá»‡u Ä‘áº·c trÆ°ng
- 50-69%: Triá»‡u chá»©ng khá»›p nhÆ°ng CHUNG CHUNG (nhiá»u bá»‡nh cÅ©ng cÃ³ triá»‡u chá»©ng tÆ°Æ¡ng tá»±)
- 30-49%: Kháº£ nÄƒng tháº¥p, chá»‰ má»™t vÃ i triá»‡u chá»©ng khá»›p
- 10-29%: Ráº¥t Ã­t kháº£ nÄƒng, nhÆ°ng váº«n cáº§n xem xÃ©t

âš ï¸ LÆ¯U Ã Vá»€ TRIá»†U CHá»¨NG CHUNG:
- "KhÃ n tiáº¿ng + khÃ³ nuá»‘t + sÆ°ng cá»•" â†’ CÃ“ THá»‚ LÃ€ BÆ°á»›u Cá»• LÃ nh TÃ­nh HOáº¶C Ung ThÆ° Thanh Quáº£n
- KHÃ”NG Ä‘Æ°a ra 80-90% náº¿u chá»‰ cÃ³ triá»‡u chá»©ng chung chung
- Ung ThÆ° thÆ°á»ng kÃ¨m: sá»¥t cÃ¢n, ho ra mÃ¡u, khÃ n tiáº¿ng kÃ©o dÃ i >3 tuáº§n, hÃºt thuá»‘c lÃ¡
- BÆ°á»›u Cá»• LÃ nh TÃ­nh thÆ°á»ng kÃ¨m: má»‡t má»i, thay Ä‘á»•i cÃ¢n náº·ng, da khÃ´, tÃ¡o bÃ³n

TRáº¢ Lá»œI THEO FORMAT:

ğŸ” PhÃ¢n tÃ­ch: [1-2 cÃ¢u phÃ¢n tÃ­ch triá»‡u chá»©ng]

ğŸ’¡ Dá»± Ä‘oÃ¡n bá»‡nh:

**TÃªn Bá»‡nh**
LÃ½ do: [Giáº£i thÃ­ch táº¡i sao triá»‡u chá»©ng khá»›p vá»›i bá»‡nh nÃ y dá»±a trÃªn database]

ğŸ“‹ THÃ”NG TIN CHI TIáº¾T Vá»€ Bá»†NH NÃ€Y:

ğŸ©º Triá»‡u chá»©ng Ä‘áº§y Ä‘á»§:
- [Triá»‡u chá»©ng 1]
- [Triá»‡u chá»©ng 2]
- [Triá»‡u chá»©ng 3]
- [Triá»‡u chá»©ng 4]

ğŸ’Š CÃ¡ch chá»¯a/Ä‘iá»u trá»‹:
- [PhÆ°Æ¡ng phÃ¡p Ä‘iá»u trá»‹ 1]
- [PhÆ°Æ¡ng phÃ¡p Ä‘iá»u trá»‹ 2]
- [PhÆ°Æ¡ng phÃ¡p Ä‘iá»u trá»‹ 3]

âš ï¸ NguyÃªn nhÃ¢n:
- [NguyÃªn nhÃ¢n 1]
- [NguyÃªn nhÃ¢n 2]

ğŸ’Š Khuyáº¿n nghá»‹:
- [Lá»i khuyÃªn cá»¥ thá»ƒ]
- [Lá»i khuyÃªn cá»¥ thá»ƒ]

QUAN TRá»ŒNG - CÃCH PHÃ‚N BIá»†T:
1. Æ¯U TIÃŠN sá»­ dá»¥ng cÃ¡c bá»‡nh tá»« pháº§n "THÃ”NG TIN Tá»ª DATABASE" á»Ÿ trÃªn
2. So sÃ¡nh Ká»¸ triá»‡u chá»©ng user vá»›i triá»‡u chá»©ng trong database:
   - Náº¿u cÃ³ thÃªm dáº¥u hiá»‡u Äáº¶C TRÆ¯NG (ho ra mÃ¡u, sá»¥t cÃ¢n, hÃºt thuá»‘c) â†’ xÃ¡c suáº¥t cao hÆ¡n
   - Náº¿u CHá»ˆ cÃ³ triá»‡u chá»©ng CHUNG CHUNG (khÃ n tiáº¿ng, khÃ³ nuá»‘t) â†’ xÃ¡c suáº¥t tháº¥p hÆ¡n (50-65%)
3. XEM XÃ‰T NHIá»€U KHáº¢ NÄ‚NG náº¿u triá»‡u chá»©ng chung:
   - VÃ­ dá»¥: "khÃ n tiáº¿ng + khÃ³ nuá»‘t + sÆ°ng cá»•" â†’ cÃ³ thá»ƒ lÃ :
     â€¢ BÆ°á»›u Cá»• LÃ nh TÃ­nh (55% náº¿u khÃ´ng cÃ³ dáº¥u hiá»‡u ung thÆ°)
     â€¢ Ung ThÆ° Thanh Quáº£n (40% náº¿u khÃ´ng cÃ³ ho ra mÃ¡u, sá»¥t cÃ¢n)
4. KHÃ”NG Ä‘Æ°a ra 80-95% trá»« khi cÃ³ dáº¥u hiá»‡u Äáº¶C TRÆ¯NG RÃ• RÃ€NG
5. Tá»•ng % cÃ³ thá»ƒ > 100% (vÃ¬ lÃ  xÃ¡c suáº¥t Ä‘á»™c láº­p)
6. Chá»‰ dÃ¹ng tÃªn bá»‡nh CHÃNH XÃC tá»« database tiáº¿ng Viá»‡t
7. Vá»›i triá»‡u chá»©ng thai sáº£n â†’ Æ°u tiÃªn: á»i Vá»¡ Non, Sinh Non, BÄƒng Huyáº¿t Sau Sinh
8. Vá»›i sá»‘t + Ä‘au â†’ Æ°u tiÃªn: Sá»‘t Xuáº¥t Huyáº¿t, CÃºm, ViÃªm Phá»•i"""
        
        # Call Groq API (Gemini already returned above)
        response = groq_client.chat.completions.create(
            model=GROQ_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": SYSTEM_INSTRUCTION
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.15,  # Giáº£m Ä‘á»ƒ model tháº­n trá»ng hÆ¡n, khÃ´ng quÃ¡ tá»± tin
            max_tokens=2500,  # TÄƒng Ä‘á»ƒ cÃ³ Ä‘á»§ khÃ´ng gian cho thÃ´ng tin chi tiáº¿t vá» bá»‡nh
            top_p=0.9,
        )
        
        result_text = response.choices[0].message.content
        # Debug: Log raw response
        print(f"\n{'='*70}")
        print("RAW RESPONSE FROM GROQ:")
        print(f"Text length: {len(result_text)} chars")
        print(f"Finish reason: {response.choices[0].finish_reason}")
        print(f"Content:\n{result_text}")
        print(f"{'='*70}\n")
        import re
        
        # Clean text
        result_text = result_text.replace('```json', '').replace('```', '')
        
        # Extract predictions - chá»‰ láº¥y 1 bá»‡nh, khÃ´ng cÃ³ %
        predictions = []
        
        # Pattern má»›i: "**TÃªn Bá»‡nh**" hoáº·c "TÃªn Bá»‡nh" sau "ğŸ’¡ Dá»± Ä‘oÃ¡n bá»‡nh:"
        disease_name = None
        
        # TÃ¬m pháº§n "ğŸ’¡ Dá»± Ä‘oÃ¡n bá»‡nh:" vÃ  láº¥y tÃªn bá»‡nh ngay sau Ä‘Ã³
        pred_section = re.search(r'ğŸ’¡\s*Dá»± Ä‘oÃ¡n bá»‡nh:\s*\n+\*\*([^*\n]+)\*\*', result_text, re.IGNORECASE)
        if pred_section:
            disease_name = pred_section.group(1).strip()
        else:
            # Fallback: tÃ¬m pattern Ä‘Æ¡n giáº£n hÆ¡n
            pred_section = re.search(r'ğŸ’¡\s*Dá»± Ä‘oÃ¡n bá»‡nh:\s*\n+([^\n]+)', result_text, re.IGNORECASE)
            if pred_section:
                disease_name = pred_section.group(1).strip()
                # Remove kÃ½ tá»± Ä‘áº·c biá»‡t
                disease_name = disease_name.replace('**', '').replace('*', '').strip()
        
        if disease_name:
            # TÃ¬m lÃ½ do
            reason = ""
            reason_match = re.search(r'LÃ½ do:\s*([^\n]+(?:\n(?!ğŸ“‹|ğŸ’Š|âš ï¸)[^\n]+)*)', result_text, re.IGNORECASE | re.DOTALL)
            if reason_match:
                reason = reason_match.group(1).strip()
                reason = re.sub(r'\s+', ' ', reason)[:300]
            
            if not reason:
                reason = "Triá»‡u chá»©ng khá»›p vá»›i bá»‡nh nÃ y dá»±a trÃªn phÃ¢n tÃ­ch database"
            
            predictions.append({
                'disease': disease_name,
                'probability': 0,  # KhÃ´ng hiá»ƒn thá»‹ %
                'reason': reason
            })
        
        # Extract recommendations
        recommendations = []
        rec_patterns = [
            r'ğŸ’Š\s*Khuyáº¿n nghá»‹:(.*?)(?=\n\n|âš ï¸|$)',
            r'Khuyáº¿n nghá»‹:(.*?)(?=\n\n|âš ï¸|$)',
            r'Lá»i khuyÃªn:(.*?)(?=\n\n|âš ï¸|$)'
        ]
        
        for pattern in rec_patterns:
            rec_match = re.search(pattern, result_text, re.DOTALL | re.IGNORECASE)
            if rec_match:
                rec_text = rec_match.group(1)
                # Extract bullet points
                rec_items = re.findall(r'[-â€¢]\s*([^\n]+)', rec_text)
                recommendations = [r.strip() for r in rec_items if len(r.strip()) > 10][:5]
                break
        
        if not recommendations:
            recommendations = [
                'Nghá»‰ ngÆ¡i Ä‘áº§y Ä‘á»§',
                'Uá»‘ng nhiá»u nÆ°á»›c',
                'Theo dÃµi triá»‡u chá»©ng',
                'Äi khÃ¡m bÃ¡c sÄ© náº¿u tÃ¬nh tráº¡ng xáº¥u Ä‘i'
            ]
        
        # Extract analysis
        analysis = "Dá»±a trÃªn cÃ¡c triá»‡u chá»©ng báº¡n mÃ´ táº£"
        analysis_patterns = [
            r'ğŸ”\s*PhÃ¢n tÃ­ch:\s*([^\n]+(?:\n(?!ğŸ’¡|\d+\.)[^\n]+)*)',
            r'PhÃ¢n tÃ­ch:\s*([^\n]+(?:\n(?!\d+\.)[^\n]+)*)'
        ]
        
        for pattern in analysis_patterns:
            analysis_match = re.search(pattern, result_text, re.IGNORECASE)
            if analysis_match:
                analysis = analysis_match.group(1).strip()
                analysis = re.sub(r'\s+', ' ', analysis)[:250]
                break
        
        # Extract detailed info about top disease
        disease_info = None
        if predictions and len(predictions) > 0:
            top_disease = predictions[0]['disease']
            
            # Extract full symptoms
            symptoms_detail = []
            symptoms_patterns = [
                r'ğŸ©º\s*Triá»‡u chá»©ng Ä‘áº§y Ä‘á»§:(.*?)(?=ğŸ’Š|âš ï¸|\n\n[ğŸ”ğŸ’¡ğŸ“‹])',
                r'Triá»‡u chá»©ng Ä‘áº§y Ä‘á»§:(.*?)(?=CÃ¡ch chá»¯a|NguyÃªn nhÃ¢n|\n\n)'
            ]
            for pattern in symptoms_patterns:
                symptoms_match = re.search(pattern, result_text, re.DOTALL | re.IGNORECASE)
                if symptoms_match:
                    symptoms_text = symptoms_match.group(1)
                    symptoms_detail = re.findall(r'[-â€¢]\s*([^\n]+)', symptoms_text)
                    symptoms_detail = [s.strip() for s in symptoms_detail if len(s.strip()) > 5][:10]
                    break
            
            # Extract treatment methods
            treatment = []
            treatment_patterns = [
                r'ğŸ’Š\s*CÃ¡ch chá»¯a/Ä‘iá»u trá»‹:(.*?)(?=âš ï¸|ğŸ’Š\s*Khuyáº¿n nghá»‹|\n\n[ğŸ”ğŸ’¡ğŸ“‹])',
                r'CÃ¡ch chá»¯a/Ä‘iá»u trá»‹:(.*?)(?=NguyÃªn nhÃ¢n|Khuyáº¿n nghá»‹|\n\n)'
            ]
            for pattern in treatment_patterns:
                treatment_match = re.search(pattern, result_text, re.DOTALL | re.IGNORECASE)
                if treatment_match:
                    treatment_text = treatment_match.group(1)
                    treatment = re.findall(r'[-â€¢]\s*([^\n]+)', treatment_text)
                    treatment = [t.strip() for t in treatment if len(t.strip()) > 5][:10]
                    break
            
            # Extract causes
            causes = []
            causes_patterns = [
                r'âš ï¸\s*NguyÃªn nhÃ¢n:(.*?)(?=ğŸ’Š|ğŸ“‹|\n\n[ğŸ”ğŸ’¡])',
                r'NguyÃªn nhÃ¢n:(.*?)(?=CÃ¡ch chá»¯a|Khuyáº¿n nghá»‹|\n\n)'
            ]
            for pattern in causes_patterns:
                causes_match = re.search(pattern, result_text, re.DOTALL | re.IGNORECASE)
                if causes_match:
                    causes_text = causes_match.group(1)
                    causes = re.findall(r'[-â€¢]\s*([^\n]+)', causes_text)
                    causes = [c.strip() for c in causes if len(c.strip()) > 5][:8]
                    break
            
            # Build disease info
            if symptoms_detail or treatment or causes:
                disease_info = {
                    'disease_name': top_disease,
                    'symptoms': symptoms_detail if symptoms_detail else ['ThÃ´ng tin sáº½ Ä‘Æ°á»£c cáº­p nháº­t'],
                    'treatment': treatment if treatment else ['Vui lÃ²ng Ä‘i khÃ¡m bÃ¡c sÄ© Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n Ä‘iá»u trá»‹ cá»¥ thá»ƒ'],
                    'causes': causes if causes else ['Nhiá»u nguyÃªn nhÃ¢n khÃ¡c nhau']
                }
        
        # Fallback náº¿u khÃ´ng cÃ³ predictions - tÃ¬m bá»‡nh tá»« database
        if not predictions and relevant_diseases:
            # Láº¥y bá»‡nh Ä‘áº§u tiÃªn tá»« database search
            disease_name = relevant_diseases[0]
            predictions.append({
                'disease': disease_name,
                'probability': 0,
                'reason': f'Triá»‡u chá»©ng khá»›p vá»›i {disease_name} dá»±a trÃªn phÃ¢n tÃ­ch database'
            })
        
        # ThÃªm thÃ´ng tin chi tiáº¿t tá»« database cho tá»«ng bá»‡nh Ä‘Æ°á»£c dá»± Ä‘oÃ¡n
        detailed_predictions = []
        for pred in predictions:
            disease_name = pred['disease']
            
            # Láº¥y triá»‡u chá»©ng Ä‘iá»ƒn hÃ¬nh tá»« database
            typical_symptoms = []
            if disease_name in disease_symptoms:
                symptom_samples = disease_symptoms[disease_name][:5]  # Top 5 triá»‡u chá»©ng
                for symptom in symptom_samples:
                    # Clean symptom text
                    clean = symptom.replace("TÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬?", "")
                    clean = clean.replace('"', '').strip()
                    clean = re.sub(r'^(TÃ´i|Bá»‡nh nhÃ¢n)\s+(Ä‘ang|hiá»‡n Ä‘ang|Ä‘ang cáº£m tháº¥y|cáº£m tháº¥y|hay bá»‹|bá»‹)\s+', '', clean)
                    clean = re.sub(r'^\s*cÃ³ cÃ¡c triá»‡u chá»©ng nhÆ°\s+', '', clean)
                    if clean and len(clean) > 10:
                        typical_symptoms.append(clean)
            
            # Äáº¿m sá»‘ máº«u trong database
            sample_count = len(df[df['Disease'] == disease_name])
            
            detailed_predictions.append({
                'disease': disease_name,
                'probability': pred['probability'],
                'reason': pred['reason'],
                'typical_symptoms': typical_symptoms[:3],  # Top 3 triá»‡u chá»©ng Ä‘iá»ƒn hÃ¬nh
                'database_samples': sample_count,
                'has_database_info': len(typical_symptoms) > 0
            })
        
        # Láº¥y cÃ¡c bá»‡nh liÃªn quan khÃ¡c (tá»« káº¿t quáº£ tÃ¬m kiáº¿m nhÆ°ng khÃ´ng Ä‘Æ°á»£c dá»± Ä‘oÃ¡n)
        predicted_diseases = [p['disease'] for p in predictions]
        related_diseases = []
        for disease in relevant_diseases[:15]:  # Top 15 tá»« database
            if disease not in predicted_diseases:
                sample_count = len(df[df['Disease'] == disease])
                # Láº¥y 1-2 triá»‡u chá»©ng Ä‘iá»ƒn hÃ¬nh
                symptoms = []
                if disease in disease_symptoms:
                    for s in disease_symptoms[disease][:2]:
                        clean = re.sub(r'TÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬\?|"', '', s).strip()
                        clean = re.sub(r'^(TÃ´i|Bá»‡nh nhÃ¢n)\s+(Ä‘ang|hiá»‡n Ä‘ang|cáº£m tháº¥y|hay bá»‹|bá»‹)\s+', '', clean)
                        if clean and len(clean) > 10:
                            symptoms.append(clean[:80])  # Limit length
                
                related_diseases.append({
                    'disease': disease,
                    'sample_symptoms': symptoms[:2],
                    'database_samples': sample_count
                })
                if len(related_diseases) >= 5:  # Chá»‰ láº¥y 5 bá»‡nh liÃªn quan
                    break
        
        # Final result vá»›i thÃ´ng tin Ä‘áº§y Ä‘á»§
        result = {
            'success': True,
            'analysis': analysis,
            'predictions': detailed_predictions if detailed_predictions else [
                {
                    'disease': 'KhÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c',
                    'probability': 0,
                    'reason': 'Vui lÃ²ng mÃ´ táº£ triá»‡u chá»©ng chi tiáº¿t hÆ¡n',
                    'typical_symptoms': [],
                    'database_samples': 0,
                    'has_database_info': False
                }
            ],
            'disease_info': disease_info,  # ThÃ´ng tin chi tiáº¿t vá» bá»‡nh (triá»‡u chá»©ng Ä‘áº§y Ä‘á»§, cÃ¡ch chá»¯a, nguyÃªn nhÃ¢n)
            'recommendations': recommendations,
            'ai_engine': ai_engine,  # AI engine being used
            'warning': 'ÄÃ¢y lÃ  dá»± Ä‘oÃ¡n AI, KHÃ”NG PHáº¢I cháº©n Ä‘oÃ¡n y táº¿. HÃ£y Ä‘i khÃ¡m bÃ¡c sÄ© Ä‘á»ƒ Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n chÃ­nh xÃ¡c!',
            
            # ThÃ´ng tin bá»• sung tá»« database
            'additional_info': {
                'related_diseases': related_diseases,
                'total_diseases_analyzed': len(relevant_diseases),
                'confidence_level': 'cao' if (detailed_predictions and detailed_predictions[0]['probability'] >= 70) else 'trung bÃ¬nh' if (detailed_predictions and detailed_predictions[0]['probability'] >= 50) else 'tháº¥p'
            },
            
            # Metadata
            'metadata': {
                'source': f'{ai_engine.upper()} AI + CSV Database',
                'model': GROQ_MODEL if ai_engine == 'groq' else GEMINI_MODEL,
                'provider': ai_engine.title(),
                'database_stats': {
                    'total_diseases': len(diseases),
                    'total_symptom_samples': len(df),
                    'diseases_searched': len(relevant_diseases)
                }
            }
        }
        
        # LÆ°u lá»‹ch sá»­ vÃ o database
        if detailed_predictions and len(detailed_predictions) > 0:
            disease_name = detailed_predictions[0]['disease']
            confidence = detailed_predictions[0].get('probability', 0)
            save_search_history(symptoms, disease_name, analysis, confidence)
        
        return jsonify(result)
        
    except Exception as e:
        error_msg = str(e)
        
        # Check for quota exceeded or rate limit
        if '429' in error_msg or 'quota' in error_msg.lower() or 'rate_limit' in error_msg.lower():
            # Fallback to CSV prediction when API fails
            print("âš ï¸ API limit reached, falling back to CSV prediction")
            relevant_context, relevant_diseases, best_match_score, top_diseases_with_scores = find_relevant_diseases(symptoms, top_k=20)
            
            if top_diseases_with_scores and len(top_diseases_with_scores) >= 3:
                result = predict_from_csv_data(symptoms, top_diseases_with_scores, ai_engine='groq')  # Fallback to groq
                if result:
                    result['warning'] = 'âš ï¸ API háº¿t quota - Káº¿t quáº£ tá»« CSV database. HÃ£y Ä‘i khÃ¡m bÃ¡c sÄ© Ä‘á»ƒ Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n chÃ­nh xÃ¡c!'
                    result['source'] = 'CSV Database (API unavailable)'
                    result['ai_engine'] = 'csv_fallback'
                    return jsonify(result)
            
            return jsonify({
                'error': 'âŒ Háº¾T QUOTA/RATE LIMIT API',
                'analysis': f'API key Ä‘Ã£ háº¿t quota hoáº·c vÆ°á»£t rate limit',
                'predictions': [
                    {'disease': 'KhÃ´ng thá»ƒ dá»± Ä‘oÃ¡n', 'probability': 0, 'reason': 'API key háº¿t quota/rate limit'}
                ],
                'recommendations': [
                    'â° Chá» má»™t chÃºt Ä‘á»ƒ rate limit reset',
                    'ğŸ’³ Kiá»ƒm tra quota táº¡i: https://console.groq.com',
                    'ğŸ”‘ Táº¡o API key má»›i náº¿u cáº§n',
                    'ğŸ’» Groq cÃ³ free tier ráº¥t generous'
                ],
                'warning': 'âš ï¸ Háº¾T QUOTA/RATE LIMIT - Vui lÃ²ng Ä‘á»£i hoáº·c kiá»ƒm tra API key',
                'source': 'Error'
            }), 429
        
        # Other errors - fallback to CSV
        print(f"ERROR: {error_msg}")
        print("âš ï¸ Error occurred, falling back to CSV prediction")
        
        try:
            relevant_context, relevant_diseases, best_match_score, top_diseases_with_scores = find_relevant_diseases(symptoms, top_k=20)
            
            if top_diseases_with_scores and len(top_diseases_with_scores) >= 3:
                result = predict_from_csv_data(symptoms, top_diseases_with_scores, ai_engine='groq')  # Fallback to groq
                if result:
                    result['warning'] = f'âš ï¸ API lá»—i - Káº¿t quáº£ tá»« CSV database. HÃ£y Ä‘i khÃ¡m bÃ¡c sÄ©!'
                    result['source'] = 'CSV Database (API error fallback)'
                    result['ai_engine'] = 'csv_fallback'
                    return jsonify(result)
        except Exception as csv_error:
            print(f"CSV fallback also failed: {csv_error}")
        
        return jsonify({
            'error': f'Lá»—i: {error_msg[:100]}',
            'analysis': 'CÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ yÃªu cáº§u',
            'predictions': [
                {'disease': 'Lá»—i há»‡ thá»‘ng', 'probability': 0, 'reason': 'Vui lÃ²ng thá»­ láº¡i sau'}
            ],
            'recommendations': [
                'Kiá»ƒm tra káº¿t ná»‘i internet',
                'Thá»­ láº¡i sau vÃ i giÃ¢y',
                'Kiá»ƒm tra console Ä‘á»ƒ xem chi tiáº¿t lá»—i'
            ],
            'warning': 'âš ï¸ CÃ³ lá»—i xáº£y ra - vui lÃ²ng thá»­ láº¡i',
            'source': 'Error'
        }), 500

@app.route('/stats')
def stats():
    """
    Endpoint tráº£ vá» thá»‘ng kÃª chi tiáº¿t vá» database vÃ  system
    """
    # TÃ­nh toÃ¡n thá»‘ng kÃª
    disease_sample_counts = df['Disease'].value_counts().to_dict()
    top_10_diseases = dict(list(disease_sample_counts.items())[:10])
    
    # TÃ­nh avg samples per disease
    avg_samples = len(df) / len(diseases)
    
    return jsonify({
        'success': True,
        'database': {
            'total_diseases': len(diseases),
            'total_symptom_samples': len(df),
            'avg_samples_per_disease': round(avg_samples, 2),
            'top_10_diseases_by_samples': top_10_diseases,
            'diseases_list_sample': diseases[:20]  # 20 bá»‡nh Ä‘áº§u tiÃªn
        },
        'model': {
            'engines': {
                'groq': GROQ_MODEL,
                'gemini': GEMINI_MODEL
            },
            'default': DEFAULT_AI_ENGINE,
            'type': 'Dual AI Engine with TF-IDF + CSV Database',
            'features': [
                'TF-IDF based disease matching',
                'Database-driven symptom analysis',
                'Context-aware prediction',
                'Typical symptoms from real data'
            ]
        },
        'api': {
            'version': '2.0',
            'endpoints': {
                '/predict': 'POST - Dá»± Ä‘oÃ¡n bá»‡nh tá»« triá»‡u chá»©ng',
                '/stats': 'GET - Thá»‘ng kÃª há»‡ thá»‘ng',
                '/': 'GET - Giao diá»‡n web'
            },
            'response_fields': [
                'analysis',
                'predictions (with typical_symptoms)',
                'recommendations',
                'additional_info (related_diseases)',
                'metadata (database_stats)'
            ]
        },
        'accuracy': {
            'estimated': '85-95%',
            'notes': 'Dá»±a trÃªn 23,520 máº«u triá»‡u chá»©ng thá»±c táº¿',
            'confidence_levels': {
                'high': 'probability >= 70%',
                'medium': '50% <= probability < 70%',
                'low': 'probability < 50%'
            }
        }
    })

@app.route('/diseases')
def get_diseases():
    """
    Endpoint tráº£ vá» danh sÃ¡ch táº¥t cáº£ cÃ¡c bá»‡nh
    """
    disease_list = []
    for disease in sorted(diseases):
        sample_count = len(df[df['Disease'] == disease])
        disease_list.append({
            'disease': disease,
            'sample_count': sample_count
        })
    
    return jsonify({
        'success': True,
        'total': len(disease_list),
        'diseases': disease_list
    })

@app.route('/disease/<disease_name>')
def get_disease_info(disease_name):
    """
    Endpoint tráº£ vá» thÃ´ng tin chi tiáº¿t vá» má»™t bá»‡nh cá»¥ thá»ƒ
    """
    if disease_name not in diseases:
        return jsonify({
            'success': False,
            'error': f'Bá»‡nh "{disease_name}" khÃ´ng cÃ³ trong database'
        }), 404
    
    # Láº¥y táº¥t cáº£ triá»‡u chá»©ng cá»§a bá»‡nh nÃ y
    disease_data = df[df['Disease'] == disease_name]['Question'].tolist()
    
    # Clean symptoms
    symptoms = []
    for symptom in disease_data[:20]:  # Top 20 triá»‡u chá»©ng
        clean = symptom.replace("TÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬?", "")
        clean = clean.replace('"', '').strip()
        clean = re.sub(r'^(TÃ´i|Bá»‡nh nhÃ¢n)\s+(Ä‘ang|hiá»‡n Ä‘ang|cáº£m tháº¥y|hay bá»‹|bá»‹)\s+', '', clean)
        clean = re.sub(r'^\s*cÃ³ cÃ¡c triá»‡u chá»©ng nhÆ°\s+', '', clean)
        if clean and len(clean) > 10:
            symptoms.append(clean)
    
    return jsonify({
        'success': True,
        'disease': disease_name,
        'total_samples': len(disease_data),
        'typical_symptoms': symptoms[:10],  # Top 10
        'all_symptom_variations': len(disease_data)
    })

@app.route('/history', methods=['GET'])
def get_history():
    """Láº¥y danh sÃ¡ch lá»‹ch sá»­ tÃ¬m kiáº¿m"""
    try:
        conn = get_db_connection()
        if not conn:
            return jsonify({'success': False, 'error': 'Database connection failed'}), 500
        
        cursor = conn.cursor(dictionary=True)
        
        # Láº¥y 50 lá»‹ch sá»­ gáº§n nháº¥t
        query = """
            SELECT id, symptoms, disease, analysis, confidence, created_at
            FROM search_history
            ORDER BY created_at DESC
            LIMIT 50
        """
        cursor.execute(query)
        history = cursor.fetchall()
        
        # Convert datetime to string
        for item in history:
            if item['created_at']:
                item['created_at'] = item['created_at'].isoformat()
        
        return jsonify({
            'success': True,
            'history': history
        })
        
    except Error as e:
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if conn and conn.is_connected():
            cursor.close()
            conn.close()

@app.route('/history/<int:history_id>', methods=['GET'])
def get_history_item(history_id):
    """Láº¥y chi tiáº¿t 1 lá»‹ch sá»­"""
    try:
        conn = get_db_connection()
        if not conn:
            return jsonify({'success': False, 'error': 'Database connection failed'}), 500
        
        cursor = conn.cursor(dictionary=True)
        query = "SELECT * FROM search_history WHERE id = %s"
        cursor.execute(query, (history_id,))
        item = cursor.fetchone()
        
        if item:
            if item['created_at']:
                item['created_at'] = item['created_at'].isoformat()
            return jsonify({'success': True, 'data': item})
        else:
            return jsonify({'success': False, 'error': 'Not found'}), 404
            
    except Error as e:
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if conn and conn.is_connected():
            cursor.close()
            conn.close()

@app.route('/history/delete/<int:history_id>', methods=['DELETE'])
def delete_history_item(history_id):
    """XÃ³a 1 lá»‹ch sá»­"""
    try:
        conn = get_db_connection()
        if not conn:
            return jsonify({'success': False, 'error': 'Database connection failed'}), 500
        
        cursor = conn.cursor()
        query = "DELETE FROM search_history WHERE id = %s"
        cursor.execute(query, (history_id,))
        conn.commit()
        
        if cursor.rowcount > 0:
            return jsonify({'success': True, 'message': 'Deleted successfully'})
        else:
            return jsonify({'success': False, 'error': 'Not found'}), 404
            
    except Error as e:
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if conn and conn.is_connected():
            cursor.close()
            conn.close()

@app.route('/history/clear', methods=['DELETE'])
def clear_all_history():
    """XÃ³a toÃ n bá»™ lá»‹ch sá»­"""
    try:
        conn = get_db_connection()
        if not conn:
            return jsonify({'success': False, 'error': 'Database connection failed'}), 500
        
        cursor = conn.cursor()
        query = "DELETE FROM search_history"
        cursor.execute(query)
        conn.commit()
        
        deleted_count = cursor.rowcount
        
        return jsonify({
            'success': True,
            'message': f'Cleared {deleted_count} records',
            'count': deleted_count
        })
            
    except Error as e:
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if conn and conn.is_connected():
            cursor.close()
            conn.close()

if __name__ == '__main__':
    print("="*70)
    print("ğŸŒ SMART DISEASE DIAGNOSIS WEB APP")
    print("="*70)
    print(f"ğŸ“Š Database: {len(diseases)} loáº¡i bá»‡nh, {len(df)} máº«u triá»‡u chá»©ng")
    print(f"ğŸ¤– AI Engines: Groq ({GROQ_MODEL}) + Gemini ({GEMINI_MODEL})")
    print(f"âš¡ Strategy: CSV First â†’ Groq API Fallback")
    print(f"ğŸ¯ CSV Threshold: {CSV_CONFIDENCE_THRESHOLD} (Ä‘iá»u chá»‰nh Ä‘á»ƒ tá»‘i Æ°u)")
    print(f"\nğŸ’¡ Lá»£i Ã­ch:")
    print(f"   â€¢ Nhanh: Dá»± Ä‘oÃ¡n tá»« CSV khÃ´ng cáº§n gá»i API")
    print(f"   â€¢ Tiáº¿t kiá»‡m: Giáº£m API calls khi cÃ³ káº¿t quáº£ tá»‘t tá»« CSV")
    print(f"   â€¢ ChÃ­nh xÃ¡c: DÃ¹ng Groq AI khi cáº§n phÃ¢n tÃ­ch phá»©c táº¡p")
    # Get port from environment variable (Railway/Heroku sets this automatically)
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    
    print(f"\nğŸš€ Starting server...")
    print(f"ğŸ“ URL: http://0.0.0.0:{port}")
    print(f"ğŸ”§ Debug mode: {debug}")
    print(f"\nâš ï¸  Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng server")
    print("="*70)
    
    app.run(debug=debug, host='0.0.0.0', port=port)

